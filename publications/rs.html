<!DOCTYPE HTML>
<html>
	<head>
		<title>Paper: FBI</title>
		<meta charset="utf-8" />
		<link rel="icon" type="image/png" href="./images/favicon2.png" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
	</head>
	<body class="is-preload">


		<div class="topnav">
			<a href="../index.html#three">Contact</a>
			<a href="../index.html#two">Publications</a>
			<a href="../index.html#news">News</a>
			<a class="active" href="../index.html">Home</a>
		  </div>


		<div id="publication">

			<div>
				<!-- <form action="../index.html#two" style="display:flex; justify-content:flex-end;">
					<input type="submit" value="Back to the papers" />
				</form> -->

				<header class="major">
					<h2>Randomized Smoothing Under Attack: How Good is it in Practice?</h2>
					<p>
						<a href="../index.html">Thibault MAHO</a>, 
						<a href="http://people.rennes.inria.fr/Teddy.Furon">Teddy FURON</a>, 
						<a href=https://erwanlemerrer.github.io>Erwan LE MERRER</a> <br />
					IEEE ICASSP 2022
					</p>
				</header>

				<div class="inner">
					<ul class="icons">
						<!-- <li><a href="https://github.com/t-maho/SurFree" class="icon brands fa-github"><span class="label">Github</span></a></li> -->
						<!-- <li><a href="./pdf/rs.pdf" class="icon far fa-file-pdf" target="_blank"><span class="label">PDF</span></a></li> -->
						<li><a href="https://arxiv.org/abs/2204.14187" target="_blank"><span>Arxiv</span></a></li>
						<!-- <li><a href="./pdf/surfree_poster_cvpr2021.pdf"><span>Poster</span></a></li> -->
						<!-- <li><a href="#"><span>Video (Not available)</span></a></li> -->
					</ul>
				</div>
			</div>
			
			<div>
				<h2>Abstract</h2>
				<p> 
					Randomized smoothing is a recent and celebrated solution to certify the robustness of any 
					classifier. While it indeed provides a theoretical robustness against adversarial attacks, 
					the dimensionality of current classifiers necessarily imposes Monte Carlo approaches for its 
					application in practice.This paper questions the effectiveness of randomized smoothing as a 
					defense, against state of the art black-box attacks. This is a novel perspective, as previous 
					research works considered the certification as an unquestionable guarantee. We first formally 
					highlight the mismatch between a theoretical certification and the practice of attacks on 
					classifiers. We then perform attacks on randomized smoothing as a defense. Our main observation 
					is that there is a major mismatch in the settings of the RS for obtaining high certified robustness 
					or when defeating black box attacks while preserving the classifier accuracy.
				</p>
				<iframe src="./pdf/rs.pdf" width="100%" height="800"></iframe>
			</div>

			<!-- <div class="image fit">
				<img src="../images//surfree_image.jpg" alt="" />
			</div> -->

		</div>

	<!-- Scripts -->
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/jquery.poptrox.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="assets/js/main.js"></script>
            

	</body>
</html>